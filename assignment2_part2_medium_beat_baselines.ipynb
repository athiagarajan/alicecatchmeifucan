{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2_part2_medium_beat_baselines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athiagarajan/alicecatchmeifucan/blob/master/assignment2_part2_medium_beat_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zYfXG7GWEX6I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/athiagarajan/alicecatchmeifucan/img/ods_stickers.jpg?raw=1\" />\n",
        "    \n",
        "## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
        "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
      ]
    },
    {
      "metadata": {
        "id": "rtBVT9d5EX6K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# <center> Assignment #2. Spring 2019\n",
        "## <center>  Competition 2. Predicting Medium articles popularity with Ridge Regression <br>(beating baselines in the \"Medium\" competition)\n",
        "    \n",
        "<img src='https://github.com/athiagarajan/alicecatchmeifucan/img/medium_claps.jpg?raw=1' width=40% />\n",
        "\n",
        "\n",
        "In this [competition](https://www.kaggle.com/c/how-good-is-your-medium-article) we are predicting Medium article popularity based on its features like content, title, author, tags, reading time etc. \n",
        "\n",
        "Prior to working on the assignment, you'd better check out the corresponding course material:\n",
        " 1. [Classification, Decision Trees and k Nearest Neighbors](https://nbviewer.jupyter.org/github/Yorko/mlcourse_open/blob/master/jupyter_english/topic03_decision_trees_kNN/topic3_decision_trees_kNN.ipynb?flush_cache=true), the same as an interactive web-based [Kaggle Kernel](https://www.kaggle.com/kashnitsky/topic-3-decision-trees-and-knn) (basics of machine learning are covered here)\n",
        " 2. Linear classification and regression in 5 parts: \n",
        "    - [ordinary least squares](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-1-ols)\n",
        "    - [linear classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification)\n",
        "    - [regularization](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-3-regularization)\n",
        "    - [logistic regression: pros and cons](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit)\n",
        "    - [validation](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-5-validation)\n",
        " 3. You can also practice with demo assignments, which are simpler and already shared with solutions: \n",
        "    - \"Sarcasm detection with logistic regression\": [assignment](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit) + [solution](https://www.kaggle.com/kashnitsky/a4-demo-sarcasm-detection-with-logit-solution)\n",
        "    - \"Linear regression as optimization\": [assignment](https://www.kaggle.com/kashnitsky/a4-demo-linear-regression-as-optimization/edit) (solution cannot be officially shared)\n",
        "    - \"Exploring OLS, Lasso and Random Forest in a regression task\": [assignment](https://www.kaggle.com/kashnitsky/a6-demo-linear-models-and-rf-for-regression) + [solution](https://www.kaggle.com/kashnitsky/a6-demo-regression-solution)\n",
        " 4. Baseline with Ridge regression and \"bag of words\" for article content, [Kernel](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline)\n",
        " 5. Other [Kernels](https://www.kaggle.com/c/how-good-is-your-medium-article/kernels?sortBy=voteCount&group=everyone&pageSize=20&competitionId=8673) in this competition. You can share yours as well, but not high-performing ones (Public LB MAE shall be > 1.5). Please don't spoil the competitive spirit.  \n",
        " 6. If that's still not enough, watch two videos (Linear regression and regularization) from here [mlcourse.ai/video](https://mlcourse.ai/video), the second one on LTV prediction is smth that you won't typically find in a MOOC - real problem, real metrics, real data.\n",
        "\n",
        "**Your task:**\n",
        " 1. \"Freeride\". Come up with good features to beat the baselines \"A2 baseline (10 credits)\" (**1.45082** Public LB MAE) and \"A2 strong baseline (20 credits)\"  (**1.41117** Public LB MAE). As names suggest, you'll get 10 more credits for beating the first one, and 10 more (20 in total) for beating the second one. You need to name your [team](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/team) (out of 1 person) in full accordance with the [course rating](https://docs.google.com/spreadsheets/d/1LAy1eK8vIONzIWgcCEaVmhKPSj579zK5lrECf_tQT60/edit?usp=sharing) (for newcomers: you need to name your team with your real full name). You can think of it as a part of the assignment.\n",
        " 2. If you've beaten \"A2 baseline (10 credits)\" or performed better, you need to upload your solution as described in [course roadmap](https://mlcourse.ai/roadmap) (\"Kaggle Inclass Competition Medium\"). For all baselines that you see on Public Leaderboard, it's OK to beat them on Public LB as well. But 10 winners will be defined according to the private LB, which will be revealed by @yorko on March 11. \n",
        " \n",
        "### <center> Deadline for A2: 2019 March 10, 20:59 GMT (London time)\n",
        " \n",
        "### How to get help\n",
        "In [ODS Slack](https://opendatascience.slack.com) (if you still don't have access, fill in the [form](https://docs.google.com/forms/d/1BMqcUc-hIQXa0HB_Q2Oa8vWBtGHXk8a6xo5gPnMKYKA/edit) mentioned on the mlcourse.ai main page), we have a channel **#mlcourse_ai_news** with announcements from the course team.\n",
        "You can discuss the course content freely in the **#mlcourse_ai** channel (we still have a huge Russian-speaking group, they have a separate channel **#mlcourse_ai_rus**).\n",
        "\n",
        "Please stick this special thread for your questions:\n",
        " - [#a2_medium](https://opendatascience.slack.com/archives/C91N8TL83/p1549882568052400) \n",
        " \n",
        "Help each other without sharing actual code. Our TA Artem @datamove is there to help (only in the mentioned thread, do not write to him directly)."
      ]
    },
    {
      "metadata": {
        "id": "YP6rNqhFEX6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm_notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.linear_model import Ridge\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M9YDjJ128Plo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mt_m839yEX6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following code will help to throw away all HTML tags from an article content."
      ]
    },
    {
      "metadata": {
        "id": "stcY_lN1EX6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from html.parser import HTMLParser\n",
        "\n",
        "class MLStripper(HTMLParser):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "        self.strict = False\n",
        "        self.convert_charrefs= True\n",
        "        self.fed = []\n",
        "    def handle_data(self, d):\n",
        "        self.fed.append(d)\n",
        "    def get_data(self):\n",
        "        return ''.join(self.fed)\n",
        "\n",
        "def strip_tags(html):\n",
        "    s = MLStripper()\n",
        "    s.feed(html)\n",
        "    return s.get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOAds-GVEX6V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Supplementary function to read a JSON line without crashing on escape characters."
      ]
    },
    {
      "metadata": {
        "id": "3hsYw7H_EX6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_json_line(line=None):\n",
        "    result = None\n",
        "    try:        \n",
        "        result = json.loads(line)\n",
        "    except Exception as e:      \n",
        "        # Find the offending character index:\n",
        "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
        "        # Remove the offending character:\n",
        "        new_line = list(line)\n",
        "        new_line[idx_to_replace] = ' '\n",
        "        new_line = ''.join(new_line)     \n",
        "        return read_json_line(line=new_line)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3SQg8p9EX6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
      ]
    },
    {
      "metadata": {
        "id": "LuWFDYp-EX6b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_features_and_write(path_to_data, inp_zip_filename,\n",
        "                               inp_filename, is_train=True):\n",
        "    \n",
        "    features = ['content', 'published', 'title', 'author']\n",
        "    prefix = 'train' if is_train else 'test'\n",
        "    feature_files = [open(os.path.join(path_to_data,\n",
        "                                       '{}_{}.txt'.format(prefix, feat)),\n",
        "                          'w', encoding='utf-8')\n",
        "                     for feat in features]\n",
        "    xx=''\n",
        "    #with open(os.path.join(path_to_data, inp_filename), \n",
        "              #encoding='utf-8') as inp_json_file:\n",
        "    zf = zipfile.ZipFile(os.path.join(path_to_data, inp_zip_filename))\n",
        "    #inp_json_file = zf.open(inp_filename)\n",
        "    with zf.open(inp_filename)  as inp_json_file:\n",
        "        for line in tqdm_notebook(inp_json_file):\n",
        "            json_data = read_json_line(line)\n",
        "            # You code here\n",
        "            content = json_data['content'].replace('\\n', ' ').replace('\\r', ' ')\n",
        "            content_no_html_tags = strip_tags(content)\n",
        "            feature_files[0].write(content_no_html_tags + '\\n')\n",
        "            content = json_data['published']['$date'].replace('\\n', ' ').replace('\\r', ' ')\n",
        "            content_no_html_tags = strip_tags(content.format('%Y-%m-%dT%H:%M:%S.%fZ'))\n",
        "            feature_files[1].write(content_no_html_tags + '\\n')\n",
        "            content = json_data['meta_tags']['title'].split('\\u2013')[0].strip().replace('\\n', ' ').replace('\\r', ' ')\n",
        "            content_no_html_tags = strip_tags(content)\n",
        "            feature_files[2].write(content_no_html_tags + '\\n')\n",
        "            content = json_data['meta_tags']['author'].strip()\n",
        "            #if content==None:\n",
        "              #content=' '\n",
        "            #xx=content\n",
        "            #break;\n",
        "            #content_no_html_tags = strip_tags(content)\n",
        "            feature_files[3].write(content + '\\n')\n",
        "    \n",
        "    return(xx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kqqJxrMEEX6f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_DATA = './' # modify this if you need to"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJw-d8kkEX6l",
        "colab_type": "code",
        "outputId": "5500d5a2-ede2-45f4-9c2c-1ad0d4bf7ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(extract_features_and_write(PATH_TO_DATA, 'train.json.zip', 'train.json', is_train=True))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1599cbfc19a45a2af8b1a04eb6fd341",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TlR26Su9EX6q",
        "colab_type": "code",
        "outputId": "bc549784-dc5f-4397-fe8c-66643c744790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "extract_features_and_write(PATH_TO_DATA, 'test.json.zip', 'test.json',  is_train=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6755817259f8492da5add96de540a11b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "XMFYkzQYEX6v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Add the following groups of features:**\n",
        "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
        "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
        "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
        "    - Bag of authors (i.e. One-Hot-Encoded author names)"
      ]
    },
    {
      "metadata": {
        "id": "6aA-tac7EX6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1, 2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8rMKX1a4uVPd",
        "colab_type": "code",
        "outputId": "b77aec14-d2ac-416b-d034-4c8c270b191c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with open('train_title.txt', encoding='utf-8') as input_train_file:\n",
        "    X_train_title_sparse = tfidf.fit_transform(input_train_file)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.06 s, sys: 67 ms, total: 2.12 s\n",
            "Wall time: 2.13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DBbK3Qo5yNPO",
        "colab_type": "code",
        "outputId": "e596eeb5-02b4-481a-ec23-025faddb3978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with open('test_title.txt', encoding='utf-8') as input_train_file:\n",
        "    X_test_title_sparse = tfidf.fit_transform(input_train_file)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.18 s, sys: 26 ms, total: 1.21 s\n",
            "Wall time: 1.21 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rBHWvaE1uvLO",
        "colab_type": "code",
        "outputId": "32cef25e-ed07-4cc8-f526-0d8d2c77747e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with open('train_content.txt', encoding='utf-8') as input_train_file:\n",
        "    X_train_content_sparse = tfidf.fit_transform(input_train_file)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0b9570c457ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with open('train_content.txt', encoding='utf-8') as input_train_file:\\n    X_train_content_sparse = tfidf.fit_transform(input_train_file)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tfidf' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ef8BwuY_yUfY",
        "colab_type": "code",
        "outputId": "1f8d285b-87bc-4298-fdb4-f678227dc19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with open('test_content.txt', encoding='utf-8') as input_train_file:\n",
        "    X_test_content_sparse = tfidf.fit_transform(input_train_file)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 56s, sys: 1.31 s, total: 3min 58s\n",
            "Wall time: 3min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H9oLjcLaNvaK",
        "colab_type": "code",
        "outputId": "ef947a22-b1b7-41af-9611-ad67e975eb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "X_train_dttm_df=pd.read_csv('train_published.txt', header = None)\n",
        "X_train_dttm_df[0] = pd.to_datetime(X_train_dttm_df[0])\n",
        "X_train_dttm_df.head(5)\n",
        "X_train_time_feature = pd.DataFrame(index=X_train_dttm_df.index)\n",
        "X_train_time_feature['hour'] = X_train_dttm_df[0].apply(lambda ts: ts.hour).astype(np.int8)\n",
        "X_train_time_feature['dayofweek'] = X_train_dttm_df[0].apply(lambda ts: ts.dayofweek).astype(np.int8)\n",
        "X_train_time_feature['weekend'] = X_train_dttm_df[0].apply(lambda ts: ts.dayofweek > 5).astype(np.int8)\n",
        "X_train_time_feature['morning'] = X_train_dttm_df[0].apply(lambda ts: (ts.hour >= 7) & (ts.hour < 12)).astype(np.int8)\n",
        "X_train_time_feature.head() \n",
        "X_train_time_features_sparse = StandardScaler().fit_transform(X_train_time_feature[['hour']])\n",
        "X_train_time_features_sparse = StandardScaler().fit_transform(X_train_time_feature)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int8 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int8 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uVIZDePac5rz",
        "colab_type": "code",
        "outputId": "ccd1b901-dcca-4d76-f36f-13cd6af60a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "X_test_dttm_df=pd.read_csv('test_published.txt', header = None)\n",
        "X_test_dttm_df[0] = pd.to_datetime(X_test_dttm_df[0])\n",
        "X_test_dttm_df.head(5)\n",
        "X_test_time_feature = pd.DataFrame(index=X_test_dttm_df.index)\n",
        "X_test_time_feature['hour'] = X_test_dttm_df[0].apply(lambda ts: ts.hour).astype(np.int8)\n",
        "X_test_time_feature['dayofweek'] = X_test_dttm_df[0].apply(lambda ts: ts.dayofweek).astype(np.int8)\n",
        "X_test_time_feature['weekend'] = X_test_dttm_df[0].apply(lambda ts: ts.dayofweek > 5).astype(np.int8)\n",
        "X_test_time_feature['morning'] = X_test_dttm_df[0].apply(lambda ts: (ts.hour >= 7) & (ts.hour < 12)).astype(np.int8)\n",
        "X_test_time_feature.head() \n",
        "X_test_time_feature_sparse = StandardScaler().fit_transform(X_test_time_feature)\n",
        "X_test_time_feature.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int8 were all converted to float64 by StandardScaler.\n",
            "  return self.fit(X, **fit_params).transform(X)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34645, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "FbfRsz9C991F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "eeaa3cd0-2a93-46d7-e9e1-f80396b6187c"
      },
      "cell_type": "code",
      "source": [
        "X_train_author_df=pd.read_csv('train_author.txt', delimiter = \"\\n\", header = None)\n",
        "X_train_author_df.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-78591181ceba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_author_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_author.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_author_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "td1b2wKY8JRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "78969709-7894-4b52-806d-0ce1e650854a"
      },
      "cell_type": "code",
      "source": [
        "X_train_author_df=pd.read_csv('train_author.txt', delimiter = \"\\n\", header = None)\n",
        "# define example\n",
        "#data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "#values = array(data)\n",
        "values=array(X_train_author_df[0])\n",
        "#print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=True)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "#print(onehot_encoded)\n",
        "# invert first example\n",
        "#inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "#print(inverted)\n",
        "X_train_author_sparse=onehot_encoded\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18672 18672 29381 ... 11148 20527 11148]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JbfCR5BkAxwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "adf6a6d0-240e-4cb9-eff6-e693fbe72f3c"
      },
      "cell_type": "code",
      "source": [
        "X_test_author_df=pd.read_csv('test_author.txt', delimiter = \"\\n\", header = None)\n",
        "# define example\n",
        "#data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "#values = array(data)\n",
        "values=array(X_test_author_df[0])\n",
        "#print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "#print(onehot_encoded)\n",
        "# invert first example\n",
        "#inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "#print(inverted)\n",
        "X_test_author_sparse=onehot_encoded"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 6383 10333  6383 ... 12072 14839   723]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aFm_zPiUEX61",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Join all sparse matrices.**"
      ]
    },
    {
      "metadata": {
        "id": "BqgMernSEX62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "562b00fc-13a7-4cb6-8dff-c87e64604185"
      },
      "cell_type": "code",
      "source": [
        "#X_train_sparse = hstack([X_train_content_sparse, X_train_title_sparse,\n",
        "                         #X_train_author_sparse, \n",
        "                         #X_train_time_features_sparse]).tocsr()\n",
        "#X_train_sparse = hstack([X_train_title_sparse,\n",
        "                         #X_train_content_sparse, \n",
        "                         #X_train_time_features_sparse\n",
        "                         #]).tocsr()\n",
        "\n",
        "X_train_sparse = csr_matrix(hstack([X_train_content_sparse,X_train_title_sparse,\n",
        "                         X_train_author_sparse,     \n",
        "                         X_train_time_features_sparse\n",
        "                         ]))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c4c08dcc0538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m X_train_sparse = csr_matrix(hstack([X_train_content_sparse,X_train_title_sparse,\n\u001b[0m\u001b[1;32m      3\u001b[0m                          \u001b[0mX_train_author_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mX_train_time_features_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          ]))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_content_sparse' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GmD0SkZnEX65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#X_test_sparse = hstack([X_test_content_sparse, X_test_title_sparse,\n",
        "                        #X_test_author_sparse, \n",
        "                        #X_test_time_features_sparse]).tocsr()\n",
        "#X_test_sparse = hstack([X_test_content_sparse, X_test_title_sparse,\n",
        "                        #X_test_time_features_sparse]).tocsr()\n",
        "X_test_sparse = csr_matrix(hstack([X_test_title_sparse,\n",
        "                         X_test_content_sparse, \n",
        "                         X_test_time_feature_sparse\n",
        "                         ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wTBMQwMhEX6_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Read train target and split data for validation.**"
      ]
    },
    {
      "metadata": {
        "id": "5ZFTCUBoEX7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
        "                           index_col='id')\n",
        "y_train = train_target['log_recommends'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "im_xitzGEX7D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_part_size = int(0.7 * train_target.shape[0])\n",
        "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
        "y_train_part = y_train[:train_part_size]\n",
        "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
        "y_valid = y_train[train_part_size:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgQlIaRRzvVV",
        "colab_type": "code",
        "outputId": "bef665d3-2ec4-462b-85cd-069815b1b112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(y_train, bins=30, alpha=.5, color='red', \n",
        "         label='original', range=(0,10));\n",
        "plt.hist(np.log1p(y_train), bins=30, alpha=.5, color='green', \n",
        "         label='log1p', range=(0,10));\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD6CAYAAACoCZCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "68E11zYWEX7G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train a simple Ridge model and check MAE on the validation set.**"
      ]
    },
    {
      "metadata": {
        "id": "-mnDcBs3EX7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ridge = Ridge(random_state=17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vaVVhWP0NLq",
        "colab_type": "code",
        "outputId": "548cae92-0405-48d7-cd0f-442afddcd358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ridge.fit(X_train_part_sparse, np.log1p(y_train_part));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 41.4 s, sys: 26.7 ms, total: 41.4 s\n",
            "Wall time: 41.5 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "   normalize=False, random_state=17, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "7HQVzEr_EX7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
      ]
    },
    {
      "metadata": {
        "id": "QieqVo6lEX7M",
        "colab_type": "code",
        "outputId": "c3a7f7d7-f000-4bc2-de6f-8187968f5c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ridge.fit(X_train_sparse, np.log1p(y_train));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 58.5 s, sys: 37.6 ms, total: 58.6 s\n",
            "Wall time: 58.6 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "   normalize=False, random_state=17, solver='auto', tol=0.001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "jBjWn-QM2z97",
        "colab_type": "code",
        "outputId": "764eb53e-f0dd-47e4-c774-4dcf8f8dd079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ridge_test_pred = np.expm1(ridge.predict(X_test_sparse))\n",
        "print(ridge_test_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.88563419 2.31920511 1.69450504 ... 1.98462195 1.47550347 1.15184587]\n",
            "CPU times: user 148 ms, sys: 991 Âµs, total: 149 ms\n",
            "Wall time: 155 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YWcy0PipEX7T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def write_submission_file(prediction, filename,\n",
        "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
        "                                                      'sample_submission.csv')):\n",
        "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
        "    \n",
        "    submission['log_recommends'] = prediction\n",
        "    submission.to_csv(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6cSRl9XEX7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "write_submission_file(ridge_test_pred, os.path.join(PATH_TO_DATA,\n",
        "                                                    'assignment2_medium_submission.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6QmbwdFeEX7j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeros. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**\n",
        "\n",
        "**UPD:** There is a [tutorial](https://nbviewer.jupyter.org/github/Yorko/mlcourse.ai/blob/master/jupyter_english/tutorials/kaggle_leaderboard_probing_nikolai_timonin.ipynb) on leaderboard probing which is written within mlcourse.ai and is relevant here. (Originally, contestants were supposed to come up with simple probing techniques on their own. But now when this tutorial is shared, we eliminate \"discovery bias\" and equalize everybody's chances by sharing this tutorial)."
      ]
    },
    {
      "metadata": {
        "id": "H0p9YLwHEX7l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "write_submission_file(np.zeros_like(ridge_test_pred), \n",
        "                      os.path.join(PATH_TO_DATA,\n",
        "                                   'medium_all_zeros_submission.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fmHzYMoIEX7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
      ]
    },
    {
      "metadata": {
        "id": "-psOVMosEX7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ridge_test_pred_modif = ridge_test_pred # You code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxceg1cgEX7u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "write_submission_file(ridge_test_pred_modif, \n",
        "                      os.path.join(PATH_TO_DATA,\n",
        "                                   'assignment2_medium_submission_with_hack.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYUNjeecEX7y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some ideas for improvement:\n",
        "\n",
        "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
        "- You may not ignore HTML and extract some features from there\n",
        "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
        "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
        "- Try various NLP techniques like stemming and lemmatization\n",
        "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
        "- SGD and Vowpal Wabbit will learn much faster\n",
        "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
        "- In our course, we don't cover neural nets. But it's not obliged to use GRUs/LSTMs/whatever in this competition.\n",
        "\n",
        "Good luck!\n",
        "\n",
        "<img src='https://github.com/athiagarajan/alicecatchmeifucan/img/kaggle_shakeup.png?raw=1' width=50%>"
      ]
    }
  ]
}